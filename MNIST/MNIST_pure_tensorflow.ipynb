{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST \n",
    "* (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
    "* The database is also widely used for training and testing in the field of machine learning.\n",
    "* 60,000 training images and 10,000 testing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Lets start with imports:)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data from tensorflow built in tutorials datasets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format\n",
    "The data is stored in a vector format, while the original data was a 2-dimensional matrix with values representing how much of a pigment was at a certain location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Now that we know that minst.train.images in a n dimmentional array we can reshape sub arrays (images) to their original square shape\n",
    "#### Lets test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = mnist.train.images[12].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c72e400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be4bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have pretty good idea what number is it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "* Learning Rate - How quickly to adjust the cost function.\n",
    "* Training Epochs - How many training cycles to go through\n",
    "* Batch Size - Size of the 'batches' of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters\n",
    "\n",
    "Here we have parameters which will directly define our Neural Network, these would be adjusted depending on what your data looked like and what kind of a net you would want to build. Basically just some numbers we will eventually use to define some variables later on in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorFlow Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and Optimization Functions\n",
    "\n",
    "We'll use Tensorflow's built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp, ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11cbac4e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADI1JREFUeJzt3V+sVPW5xvHnORai2ZCIJRBi9UAJwoUxana4IsbGUq02\nwWo0cEVj021iTeqNqdqLmjRNTKVtGhOb0BShJ62tCW0k2hzbo+ccuWhQIC0q1oqVppCtVGlELgwF\n317Mwu4i85thZs2sBe/3k+zsmfWuP68jz17/ZubniBCAfP6j6QYANIPwA0kRfiApwg8kRfiBpAg/\nkBThB5Ii/EBShB9I6hPj3Jht3k4IjFhEuJ/5htrz277B9mu299m+b5h1ARgvD/reftvnSfqTpNWS\nDkh6UdK6iNhbWIY9PzBi49jzr5S0LyL+HBHHJP1c0poh1gdgjIYJ/8WS/jrj+YFq2r+xPWV7p+2d\nQ2wLQM1GfsEvIjZK2ihx2A+0yTB7/oOSLpnx/FPVNABngWHC/6KkZbaX2J4taa2kbfW0BWDUBj7s\nj4jjtu+W9Iyk8yRtiohXausMwEgNfKtvoI1xzg+M3Fje5APg7EX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUgMP0S1JtvdLel/SCUnHI2KyjqYAjN5Q4a98JiLeqWE9\nAMaIw34gqWHDH5J+Y3uX7ak6GgIwHsMe9q+KiIO2F0j6re0/RsTzM2eo/ijwhwFoGUdEPSuyH5R0\nNCI2FOapZ2MAuooI9zPfwIf9tidszz35WNLnJL086PoAjNcwh/0LJf3K9sn1/Cwi/ruWrgCMXG2H\n/X1tjMN+YORGftgP4OxG+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxA\nUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqo5ReoF05s2bV6yfOHGiWD9y5Eid7QyE\nPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNXzPr/tTZK+IOlQRFxeTbtI0i8kLZa0X9LtEfH30bWJ\ntrrwwguL9Q8++KBrbc6cOcVle90rX7NmTbG+dOnSrrWJiYnisr3+u9auXVus7927t1ifnJws1seh\nnz3/Zkk3nDLtPknPRsQySc9WzwGcRXqGPyKel3T4lMlrJG2pHm+RdHPNfQEYsUHP+RdGxHT1+C1J\nC2vqB8CYDP3e/ogI29GtbntK0tSw2wFQr0H3/G/bXiRJ1e9D3WaMiI0RMRkRzV/hAPCRQcO/TdL6\n6vF6SU/W0w6AcekZftuPS/qdpOW2D9j+sqSHJK22/bqkz1bPAZxFep7zR8S6LqXrau4FI3DNNdcU\n6ytWrCjW163r9r+/44orrijWe33uveTo0aPF+qxZs4r19957r2ttwYIFA/XUr173+duAd/gBSRF+\nICnCDyRF+IGkCD+QFOEHkuKru1vgggsuKNbvv//+Yv2667rfdV25cmVx2RdeeKFYv+2224r1O++8\ns1ifP39+19qOHTuKy77xxhvF+r59+4r1w4dP/Tzavyxfvry47JIlS4r10keVJem5554r1tuAPT+Q\nFOEHkiL8QFKEH0iK8ANJEX4gKcIPJOWIrt/AVf/GCl/3dS6bPXt2sb5169Zi/aabbirW33333a61\nzZs3F5d9+OGHi/VDh7p+SRNaKiLcz3zs+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKT7PPwbHjh0r\n1p9++ulifdmyZcX6ZZdd1rW2Z8+e4rLcx8+LPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNXz8/y2\nN0n6gqRDEXF5Ne1BSV+R9Ldqtgci4tc9N5b08/zDOv/884v1tWvXdq1t2LChuOwTTzxRrN91113F\nOtqnzs/zb5Z0w2mmfz8irqx+egYfQLv0DH9EPC+p+9AnAM5Kw5zz3217j+1NtufV1hGAsRg0/D+U\ntFTSlZKmJX2324y2p2zvtL1zwG0BGIGBwh8Rb0fEiYj4UNKPJHUdDTIiNkbEZERMDtokgPoNFH7b\ni2Y8/aKkl+tpB8C49PxIr+3HJV0rab7tA5K+Kela21dKCkn7JZXHaQbQOnxv/znu0UcfLdbvuOOO\nYn3BggXF+pEjR864J4wW39sPoIjwA0kRfiApwg8kRfiBpAg/kBRf3V1ZvXp1sX7vvfd2rfW6XXr9\n9dcP1FO/JiYmutamp6eLy/YaPvzWW28t1h977LFiHe3Fnh9IivADSRF+ICnCDyRF+IGkCD+QFOEH\nkuI+f+WRRx4p1kvDYPcagnv79u3Feq978QcPHizWb7nllq61Sy+9tLjs8ePHi3WG8D53secHkiL8\nQFKEH0iK8ANJEX4gKcIPJEX4gaT46u7KihUrivXS59pXruw6YJEk6eqrry7W586dW6z38uabb3at\n7d69u7hsr6/23rVr10A9oTl8dTeAIsIPJEX4gaQIP5AU4QeSIvxAUoQfSKrnfX7bl0j6iaSFkkLS\nxoj4ge2LJP1C0mJJ+yXdHhF/77Gu1t7nB84V/d7n7yf8iyQtiojdtudK2iXpZklfknQ4Ih6yfZ+k\neRHx9R7rIvzAiNX2Jp+ImI6I3dXj9yW9KuliSWskbalm26LOHwQAZ4kzOue3vVjSVZJ2SFoYESe/\nf+otdU4LAJwl+v4OP9tzJG2VdE9EHLH/dWQREdHtkN72lKSpYRsFUK++Pthje5akpyQ9ExHfq6a9\nJunaiJiurgv8X0Qs77EezvmBEavtnN+dXfyPJb16MviVbZLWV4/XS3ryTJsE0Jx+rvavkrRd0kuS\nPqwmP6DOef8Tki6V9Bd1bvUd7rEu9vzAiNV2q69OhB8YPT7PD6CI8ANJEX4gKcIPJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BUz/DbvsT2/9rea/sV21+rpj9o+6Dt31c/N46+\nXQB1cUSUZ7AXSVoUEbttz5W0S9LNkm6XdDQiNvS9Mbu8MQBDiwj3M98n+ljRtKTp6vH7tl+VdPFw\n7QFo2hmd89teLOkqSTuqSXfb3mN7k+15XZaZsr3T9s6hOgVQq56H/R/NaM+R9P+Svh0Rv7S9UNI7\nkkLSt9Q5Nbijxzo47AdGrN/D/r7Cb3uWpKckPRMR3ztNfbGkpyLi8h7rIfzAiPUb/n6u9lvSjyW9\nOjP41YXAk74o6eUzbRJAc/q52r9K0nZJL0n6sJr8gKR1kq5U57B/v6Q7q4uDpXWx5wdGrNbD/roQ\nfmD0ajvsB3BuIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyTV\n8ws8a/aOpL/MeD6/mtZGbe2trX1J9DaoOnv7z35nHOvn+T+2cXtnREw21kBBW3tra18SvQ2qqd44\n7AeSIvxAUk2Hf2PD2y9pa29t7Uuit0E10luj5/wAmtP0nh9AQxoJv+0bbL9me5/t+5rooRvb+22/\nVI083OgQY9UwaIdsvzxj2kW2f2v79er3aYdJa6i3VozcXBhZutHXrm0jXo/9sN/2eZL+JGm1pAOS\nXpS0LiL2jrWRLmzvlzQZEY3fE7Z9jaSjkn5ycjQk29+RdDgiHqr+cM6LiK+3pLcHdYYjN4+ot24j\nS39JDb52dY54XYcm9vwrJe2LiD9HxDFJP5e0poE+Wi8inpd0+JTJayRtqR5vUecfz9h16a0VImI6\nInZXj9+XdHJk6UZfu0JfjWgi/BdL+uuM5wfUriG/Q9JvbO+yPdV0M6excMbISG9JWthkM6fRc+Tm\ncTplZOnWvHaDjHhdNy74fdyqiLha0uclfbU6vG2l6Jyztel2zQ8lLVVnGLdpSd9tsplqZOmtku6J\niCMza02+dqfpq5HXrYnwH5R0yYznn6qmtUJEHKx+H5L0K3VOU9rk7ZODpFa/DzXcz0ci4u2IOBER\nH0r6kRp87aqRpbdK+mlE/LKa3Phrd7q+mnrdmgj/i5KW2V5ie7aktZK2NdDHx9ieqC7EyPaEpM+p\nfaMPb5O0vnq8XtKTDfbyb9oycnO3kaXV8GvXuhGvI2LsP5JuVOeK/xuSvtFED136+rSkP1Q/rzTd\nm6TH1TkM/Ic610a+LOmTkp6V9Lqk/5F0UYt6+y91RnPeo07QFjXU2yp1Dun3SPp99XNj069doa9G\nXjfe4QckxQU/ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ/RM9JiCPMYgt1gAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c937748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has trained 30 epochs\n"
     ]
    }
   ],
   "source": [
    "# Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Intialize all the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for generation in range(1, training_epochs + 1):\n",
    "    # Compute average loss\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(f\"Generation: {generation} cost={avg_cost:.4f}\", end='\\r')\n",
    "\n",
    "print(f\"Model has trained {training_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "\n",
    "Tensorflow comes with some built-in functions to help evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a numerical value for our predictions we will need to use tf.cast to cast the Tensor of booleans back into a Tensor of Floating point values in order to take the mean of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the tf.reduce_mean function in order to grab the mean of the elements across the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to pass in our actual test data! Now we can call the MNIST test labels and images and evaluate our accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After only 30 epochs we hot 95.5% accuracy :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
