{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST database \n",
    "### (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
    "### The database is also widely used for training and testing in the field of machine learning.\n",
    "### Contains 60,000 training images and 10,000 testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data from tensorflow built in tutorials datasets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "### The data is stored in a vector format, while the original data was a 2-dimensional matrix with values representing how much of a pigment was at a certain location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we know that minst.train.images in a n dimmentional array we can reshape sub arrays (images) to their original square shape\n",
    "#### Lets test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = mnist.train.images[12].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12643dda0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c4e2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have pretty good idea what number is it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "* Learning Rate - How quickly to adjust the cost function.\n",
    "* Training Epochs - How many training cycles to go through\n",
    "* Batch Size - Size of the 'batches' of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters\n",
    "\n",
    "Here we have parameters which will directly define our Neural Network, these would be adjusted depending on what your data looked like and what kind of a net you would want to build. Basically just some numbers we will eventually use to define some variables later on in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorFlow Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost and Optimization Functions\n",
    "\n",
    "We'll use Tensorflow's built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization of Variables\n",
    "\n",
    "Now initialize all those tf.Variable objects we created earlier. This will be the first thing we run when training our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp, ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1268f5198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPxAU4QeCIvxAUIQfCOpv82GL36qiJlAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126585978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session\n",
    "Now it is time to run our session! Pay attention to how we have two loops, the outer loop which runs the epochs, and the inner loop which runs the batches for each epoch of training. Let's breakdown each step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1 cost=176.6561\n",
      "Generation: 2 cost=44.2665\n",
      "Generation: 3 cost=28.0307\n",
      "Generation: 4 cost=19.6003\n",
      "Generation: 5 cost=14.3213\n",
      "Generation: 6 cost=10.5176\n",
      "Generation: 7 cost=7.8076\n",
      "Generation: 8 cost=5.8485\n",
      "Generation: 9 cost=4.3378\n",
      "Generation: 10 cost=3.3653\n",
      "Generation: 11 cost=2.4728\n",
      "Generation: 12 cost=1.8956\n",
      "Generation: 13 cost=1.4543\n",
      "Generation: 14 cost=1.2409\n",
      "Generation: 15 cost=0.8548\n",
      "Generation: 16 cost=0.7487\n",
      "Generation: 17 cost=0.5946\n",
      "Generation: 18 cost=0.5601\n",
      "Generation: 19 cost=0.5092\n",
      "Generation: 20 cost=0.4761\n",
      "Generation: 21 cost=0.4504\n",
      "Generation: 22 cost=0.3964\n",
      "Generation: 23 cost=0.3012\n",
      "Generation: 24 cost=0.3642\n",
      "Generation: 25 cost=0.2842\n",
      "Generation: 26 cost=0.3135\n",
      "Generation: 27 cost=0.3001\n",
      "Generation: 28 cost=0.2621\n",
      "Generation: 29 cost=0.2671\n",
      "Generation: 30 cost=0.2469\n",
      "Model has trained 30 epochs\n"
     ]
    }
   ],
   "source": [
    "# Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Intialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "for generation in range(1, training_epochs + 1):\n",
    "    # Compute average loss\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(f\"Generation: {generation} cost={avg_cost:.4f}\")\n",
    "\n",
    "print(f\"Model has trained {training_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "\n",
    "Tensorflow comes with some built-in functions to help evaluate our model, including tf.equal and tf.cast with tf.reduce_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a numerical value for our predictions we will need to use tf.cast to cast the Tensor of booleans back into a Tensor of Floating point values in order to take the mean of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the tf.reduce_mean function in order to grab the mean of the elements across the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to pass in our actual test data! Now we can call the MNIST test labels and images and evaluate our accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After only 30 epochs we hot 95.7% accuracy :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
